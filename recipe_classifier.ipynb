{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb3263b-7c05-455a-8867-6b6b95511226",
   "metadata": {},
   "source": [
    "# 🍽️🍳 مصنف وصفات الطعام \n",
    "### 🍔 🍕 🍗 🍖 🥩 🍤 🍛 🍣 🌮 🥙 🍞 🧀 🧁 🍩 🍪 🍫 🍯 🍎 🍉 🍇 🍓 🥝 🍍 🥥 🥑 🥕 🌽 🥔 🥬 🍵 ☕ 🍜 🍲 🍚 🍙 🍘 🥟 🥠 🥡 🥣 🥞 🧇 🍮 🍨 🥞 🧇 🍮 🍢 🍡 🍧 🌰 🍠 🫔 🫓 🌰 🍠 🫔 🫓 🧆 🫕 🫒 🧃 🌶 🥜\n",
    "\n",
    "### **مشروع يهدف الى تصنيف وصفات الطعام المدخلة الى احد السبع اصناف 🎯**\n",
    "- **اطباق رئيسية 🍝**\n",
    "- **مقبلات 🍟**\n",
    "- **حساء 🍲**\n",
    "- **سلطات 🥗**\n",
    "- **ساندويتشات 🥪**\n",
    "- **حلويات 🍰**\n",
    "- **مشروبات 🥤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54fd9a0d-58ca-4c5b-97b7-280a1868fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk import FreqDist \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f60e28-fbed-4ae4-86a3-74482f0fb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حذف التشويش \n",
    "def noise_removal(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # حذف وسوم HTML\n",
    "    text = re.sub(r'http\\S+', '', text)  # حذف URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # حذف علامات التنصيص\n",
    "    text = re.sub(r'\\d+', '', text)  # حذف الارقام\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a36e66a-ffb7-43b7-b4ed-85e6193b16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#حذف الكلمات التي لا تؤثر في المعنى\n",
    "def removing_stop_words(words):\n",
    "\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    \n",
    "    filtered_words = [word for word in words if word not in arabic_stopwords]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f3a919-09f6-4915-b63d-9b3ccb6c3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ارجاع الكلمات لجذرها\n",
    "def stemming(words):\n",
    "    stemmer = ISRIStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d763a7-0fa4-4c41-bc27-3815239034ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    text = noise_removal(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = removing_stop_words(tokens)\n",
    "    tokens = stemming(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e6accc1-7cff-485a-b002-01f7418e0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateBOW(wordset,doc):\n",
    "    # انشاء قاموس للكلمات الفريده وتكراره\n",
    "  fdist = FreqDist(doc)\n",
    "  return {word: fdist[word] for word in wordset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77f6be01-9648-4ff8-b095-a6bc337f3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'C:\\\\Users\\\\LENOVO\\\\Desktop\\\\recipe_classifier\\\\recipes_corpus'\n",
    "corpus = {}\n",
    "\n",
    "for file_name in os.listdir(corpus_root):\n",
    "    #عنوان الملف\n",
    "    label = file_name.split('.')[0] #حلى.txt ['حلى','txt']\n",
    "    with open(os.path.join(corpus_root, file_name), 'r', encoding='utf-8') as file:\n",
    "        corpus[label] = file.read()\n",
    "\n",
    "\n",
    "processed_corpus = {}\n",
    "for label, text in corpus.items():\n",
    "    processed_corpus[label] = text_processing(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17e3103b-2e7f-46f3-867c-9e8fa354e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب عدد تكرار الكلمات\n",
    "freq = {}\n",
    "for label in processed_corpus:\n",
    "    freq[label] = Counter(processed_corpus[label]) \n",
    "\n",
    "# حساب اعلى 100 كلمة ظهرت في كل تصنيف\n",
    "top_words = {}\n",
    "for label in processed_corpus:\n",
    "    top_words[label] = [word for word, _ in freq[label].most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1af07b12-77ec-4268-9ee3-401e3ec350ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# قائمة تجمع قوائم الوصفات\n",
    "documents = [processed_corpus[label] for label in processed_corpus]\n",
    "\n",
    "# قائمة بالاصناف\n",
    "labels = [label for label in processed_corpus]\n",
    "\n",
    "# قائمة للكلمات الفريدة\n",
    "wordset = np.unique([word for doc in documents for word in doc])\n",
    "\n",
    "bow_dicts = [calculateBOW(wordset, doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "281e4c4c-d833-48bb-9e48-d482e7f8acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# دالة تقارن بين التصنيفات وقاموس المستخدم\n",
    "\n",
    "def classify_recipes(bow_dict): #يُعرّف دالة اسمها classify_recipes تأخذ قاموس bow_dict (Bag of Words) الذي يحتوي على الكلمات من وصفة وعدد تكرار كل كلمة\n",
    "    scores = {} #ينشئ قاموس scores لحفظ \"الدرجة\" لكل تصنيف. كل تصنيف يحصل على مجموع عدد مرات ظهور كلماته المميزة.\n",
    "    \n",
    "    for label in top_words: #نبدأ حلقة تمر على كل تصنيف (مثلاً: \"حلى\"، \"طبق رئيسي\"، \"مقبلات\").\n",
    "#top_words يجب أن يكون قاموس يحتوي على الكلمات المميزة لكل تصنيف.\n",
    "\n",
    "        scores[label] = sum(bow_dict[word] for word in top_words[label] if word in bow_dict) #نحسب مجموع التكرارات للكلمات المميزة لهذا التصنيف الموجودة فعلًا في bow_dict.\n",
    "#يعني: إذا كانت الوصفة تحتوي على كلمات كثيرة تنتمي إلى تصنيف \"طبق رئيسي\"، يحصل \"طبق رئيسي\" على مجموع أكبر\n",
    "   \n",
    "    return max(scores, key=scores.get) #ترجع التصنيف الذي حصل على أعلى درجة، أي أعلى تطابق مع كلمات الوصفة.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5768c5f3-b468-4f31-9932-b52293a051d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# نص المستخدم\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m user_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mأدخل خطوات وصفة لتحديد نوعها (حلى، طبق رئيسي، مقبلات، ...): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# معالجة نص المستخدم\u001b[39;00m\n\u001b[0;32m      5\u001b[0m user_tokens \u001b[38;5;241m=\u001b[39m text_processing(user_text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# نص المستخدم\n",
    "user_text = input(\"أدخل خطوات وصفة لتحديد نوعها (حلى، طبق رئيسي، مقبلات، ...): \")\n",
    "\n",
    "# معالجة نص المستخدم\n",
    "user_tokens = text_processing(user_text)\n",
    "\n",
    "\n",
    "# تحديد التصنيف الأنسب\n",
    "predicted_class = classify_recipes(calculateBOW(wordset,user_tokens))\n",
    "print(\"🔎 تصنيف الوصفة:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
